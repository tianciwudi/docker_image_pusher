#ghcr.io/ggerganov/llama.cpp:full
#ghcr.io/ggerganov/llama.cpp:server
#ghcr.io/ggerganov/llama.cpp:server-cuda
qwenllm/qwenvl:2.5-cu121
